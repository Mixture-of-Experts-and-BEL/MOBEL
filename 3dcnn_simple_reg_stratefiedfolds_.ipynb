{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e727575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 748\n",
      "Number of label: 748\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV file\n",
    "csv_path_u= \"ssd_images_1_to_17.csv\"\n",
    "dff = pd.read_csv(csv_path_u)\n",
    "\n",
    "# Define parameters\n",
    "num_frames = 12\n",
    "height = 100\n",
    "width = 96\n",
    "channels = 3\n",
    "\n",
    "# Create an empty NumPy array with the specified shape\n",
    "sequence_of_frames = np.zeros((num_frames, height, width, channels))\n",
    "main_arr = []\n",
    "main_labels = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "cnt = 0\n",
    "for index, row in dff.iterrows():\n",
    "    # Load the image file\n",
    "    img_path = row['filepath']\n",
    "    frame_data = cv2.imread(img_path)\n",
    "    frame_data = cv2.cvtColor(frame_data, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Store frame data in sequence_of_frames array\n",
    "    sequence_of_frames[cnt] = frame_data\n",
    "    cnt += 1\n",
    "    \n",
    "    # If sequence_of_frames array is filled, append it to main_arr and reset sequence_of_frames\n",
    "    if cnt >= num_frames:\n",
    "        main_arr.append(sequence_of_frames)\n",
    "        main_labels.append(row['label'])\n",
    "        cnt = 0\n",
    "        sequence_of_frames = np.zeros((num_frames, height, width, channels))\n",
    "\n",
    "# Print the number of sequences stored in main_arr\n",
    "print(\"Number of sequences:\", len(main_arr))\n",
    "print(\"Number of label:\", len(main_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c93fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_arr = np.array(main_arr)\n",
    "main_labels = np.array(main_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5f7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 695s 17s/step - loss: 19.1982 - accuracy: 0.1566 - val_loss: 3.5922 - val_accuracy: 0.1800\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 3.4948 - accuracy: 0.1506 - val_loss: 3.4013 - val_accuracy: 0.1560\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 692s 16s/step - loss: 3.3430 - accuracy: 0.1426 - val_loss: 3.2822 - val_accuracy: 0.0880\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 686s 16s/step - loss: 3.2377 - accuracy: 0.0924 - val_loss: 3.1892 - val_accuracy: 0.0880\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 685s 16s/step - loss: 3.1516 - accuracy: 0.0924 - val_loss: 3.1103 - val_accuracy: 0.0880\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 737s 18s/step - loss: 3.0781 - accuracy: 0.0924 - val_loss: 3.0427 - val_accuracy: 0.0880\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 686s 16s/step - loss: 3.0143 - accuracy: 0.0924 - val_loss: 2.9831 - val_accuracy: 0.0880\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 682s 16s/step - loss: 2.9581 - accuracy: 0.1004 - val_loss: 2.9286 - val_accuracy: 0.1840\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 683s 16s/step - loss: 2.9074 - accuracy: 0.0904 - val_loss: 2.8814 - val_accuracy: 0.0880\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 689s 16s/step - loss: 2.8614 - accuracy: 0.0924 - val_loss: 2.8378 - val_accuracy: 0.0880\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.8200 - accuracy: 0.0924 - val_loss: 2.7981 - val_accuracy: 0.0880\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 690s 16s/step - loss: 2.7821 - accuracy: 0.0924 - val_loss: 2.7619 - val_accuracy: 0.0880\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 686s 16s/step - loss: 2.7471 - accuracy: 0.1004 - val_loss: 2.7283 - val_accuracy: 0.0880\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.7152 - accuracy: 0.1325 - val_loss: 2.6971 - val_accuracy: 0.0880\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 689s 16s/step - loss: 2.6852 - accuracy: 0.0924 - val_loss: 2.6690 - val_accuracy: 0.0880\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 685s 16s/step - loss: 2.6576 - accuracy: 0.1486 - val_loss: 2.6419 - val_accuracy: 0.1800\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 682s 16s/step - loss: 2.6316 - accuracy: 0.1305 - val_loss: 2.6167 - val_accuracy: 0.1800\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.6074 - accuracy: 0.0924 - val_loss: 2.5946 - val_accuracy: 0.0880\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 684s 16s/step - loss: 2.5848 - accuracy: 0.0924 - val_loss: 2.5721 - val_accuracy: 0.0880\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 688s 16s/step - loss: 2.5636 - accuracy: 0.0924 - val_loss: 2.5520 - val_accuracy: 0.0880\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 692s 16s/step - loss: 2.5433 - accuracy: 0.0924 - val_loss: 2.5322 - val_accuracy: 0.0880\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 691s 16s/step - loss: 2.5244 - accuracy: 0.0924 - val_loss: 2.5138 - val_accuracy: 0.0880\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.5066 - accuracy: 0.0924 - val_loss: 2.4962 - val_accuracy: 0.0880\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 690s 16s/step - loss: 2.4896 - accuracy: 0.0924 - val_loss: 2.4798 - val_accuracy: 0.0880\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 690s 16s/step - loss: 2.4738 - accuracy: 0.0924 - val_loss: 2.4639 - val_accuracy: 0.0880\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.4582 - accuracy: 0.0924 - val_loss: 2.4487 - val_accuracy: 0.0880\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 690s 16s/step - loss: 2.4436 - accuracy: 0.0924 - val_loss: 2.4345 - val_accuracy: 0.0880\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 686s 16s/step - loss: 2.4296 - accuracy: 0.0904 - val_loss: 2.4210 - val_accuracy: 0.0880\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.4164 - accuracy: 0.0924 - val_loss: 2.4085 - val_accuracy: 0.0880\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 688s 16s/step - loss: 2.4037 - accuracy: 0.0924 - val_loss: 2.3959 - val_accuracy: 0.0880\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 686s 16s/step - loss: 2.3914 - accuracy: 0.0924 - val_loss: 2.3840 - val_accuracy: 0.0880\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 688s 16s/step - loss: 2.3797 - accuracy: 0.0924 - val_loss: 2.3723 - val_accuracy: 0.0880\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 685s 16s/step - loss: 2.3686 - accuracy: 0.0924 - val_loss: 2.3618 - val_accuracy: 0.0880\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.3578 - accuracy: 0.0924 - val_loss: 2.3513 - val_accuracy: 0.0880\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 688s 16s/step - loss: 2.3473 - accuracy: 0.0924 - val_loss: 2.3405 - val_accuracy: 0.0880\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 719s 17s/step - loss: 2.3372 - accuracy: 0.0924 - val_loss: 2.3313 - val_accuracy: 0.0880\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 690s 16s/step - loss: 2.3275 - accuracy: 0.0924 - val_loss: 2.3213 - val_accuracy: 0.0880\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 688s 16s/step - loss: 2.3183 - accuracy: 0.0924 - val_loss: 2.3120 - val_accuracy: 0.0880\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.3090 - accuracy: 0.0924 - val_loss: 2.3043 - val_accuracy: 0.0880\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 689s 16s/step - loss: 2.3004 - accuracy: 0.0924 - val_loss: 2.2953 - val_accuracy: 0.0880\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 685s 16s/step - loss: 2.2918 - accuracy: 0.0924 - val_loss: 2.2865 - val_accuracy: 0.0880\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 687s 16s/step - loss: 2.2834 - accuracy: 0.0924 - val_loss: 2.2788 - val_accuracy: 0.0880\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 691s 16s/step - loss: 2.2756 - accuracy: 0.0924 - val_loss: 2.2701 - val_accuracy: 0.0880\n",
      "Epoch 44/50\n",
      "10/42 [======>.......................] - ETA: 7:44 - loss: 2.3095 - accuracy: 0.1167"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.regularizers import l1,l2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "frames = 12\n",
    "height = 100\n",
    "width = 96\n",
    "channels = 3\n",
    "input_shape = (frames, height, width, channels)\n",
    "num_classes = 6\n",
    "\n",
    "def create_3dcnn(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu', padding=\"same\", kernel_regularizer=l2(0),input_shape=input_shape))\n",
    "    model.add(MaxPooling3D((2, 2, 2), padding='same'))  \n",
    "\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', padding=\"same\",kernel_regularizer=l2(0)))\n",
    "    model.add(MaxPooling3D((2, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu', padding=\"same\",kernel_regularizer=l2(0)))\n",
    "    model.add(MaxPooling3D((2, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu', padding=\"same\",kernel_regularizer=l2(0)))\n",
    "    model.add(MaxPooling3D((2, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv3D(1024, (3, 3, 3), activation='relu', padding=\"same\",kernel_regularizer=l2(0)))\n",
    "    model.add(MaxPooling3D((2, 2, 2), padding='same'))\n",
    "    \n",
    "    #odel.add(Dropout(0.3))\n",
    "    \n",
    "    # Flatten the output for fully connected layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(Dense(1024, activation='relu',kernel_regularizer=l2(0.001))) \n",
    "    #model.add(Dropout(0.5))  \n",
    "    model.add(Dense(512, activation='relu',kernel_regularizer=l2(0.001)))\n",
    "    #model.add(Dropout(0.6))\n",
    "    model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.001)))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax')) \n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_3dcnn(input_shape, num_classes)\n",
    "\n",
    "l = LabelEncoder()\n",
    "main_labels_encoded = l.fit_transform(main_labels)\n",
    "\n",
    "# Define the number of splits for stratified cross-validation\n",
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(main_labels_encoded), y=main_labels_encoded)\n",
    "class_weights = {i: class_weights[i] for i in range(num_classes)}\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(main_arr, main_labels_encoded):\n",
    "    x_train, x_val = main_arr[train_index], main_arr[val_index]\n",
    "    y_train, y_val = main_labels_encoded[train_index], main_labels_encoded[val_index]\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=12, verbose=1,validation_data=(x_val,y_val),class_weight=class_weights, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(x_val, y_val)\n",
    "    cv_scores.append(test_accuracy)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "model.save('3DCNN_model_stratefied_reg_748.h5')\n",
    "print(\"The model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d7aac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 264\n",
      "Number of label: 264\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV file\n",
    "csv_path = \"ssd_images_19_to_24.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Define parameters\n",
    "num_frames = 12\n",
    "height = 100\n",
    "width = 96\n",
    "channels = 3\n",
    "\n",
    "# Create an empty NumPy array with the specified shape\n",
    "sequence_of_frames = np.zeros((num_frames, height, width, channels))\n",
    "main_arr_test = []\n",
    "main_labels_test = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "cnt = 0\n",
    "for index, row in df.iterrows():\n",
    "    # Load the image file\n",
    "    img_path = row['filepath']\n",
    "    frame_data = cv2.imread(img_path)\n",
    "    frame_data = cv2.cvtColor(frame_data, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Store frame data in sequence_of_frames array\n",
    "    sequence_of_frames[cnt] = frame_data\n",
    "    cnt += 1\n",
    "    \n",
    "    # If sequence_of_frames array is filled, append it to main_arr and reset sequence_of_frames\n",
    "    if cnt >= num_frames:\n",
    "        main_arr_test.append(sequence_of_frames)\n",
    "        main_labels_test.append(row['label'])\n",
    "        cnt = 0\n",
    "        sequence_of_frames = np.zeros((num_frames, height, width, channels))\n",
    "\n",
    "# Print the number of sequences stored in main_arr\n",
    "print(\"Number of sequences:\", len(main_arr_test))\n",
    "print(\"Number of label:\", len(main_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae3cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_arr_test=np.array(main_arr_test)\n",
    "main_labels_test=np.array(main_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec188be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions are: [[0.74843234 0.00717864 0.13975252 0.00802646 0.01036539 0.08624456]\n",
      " [0.77950954 0.00156497 0.16474593 0.00383554 0.00271608 0.04762793]\n",
      " [0.41486663 0.03185083 0.27474058 0.01521947 0.06359416 0.19972833]\n",
      " ...\n",
      " [0.0824692  0.305121   0.12202128 0.02562871 0.0376549  0.4271049 ]\n",
      " [0.2798407  0.06024322 0.07164983 0.02791603 0.0294737  0.5308765 ]\n",
      " [0.09997299 0.10254887 0.15725988 0.01478636 0.03380863 0.59162325]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "from keras.models import load_model\n",
    "model=load_model('3DCNN_model_stratefied_simple_748.h5')\n",
    "\n",
    "predictions = model.predict(main_arr_test)\n",
    "\n",
    "print(\"The predictions are:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16397d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd3b7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74843234 0.00717864 0.13975252 0.00802646 0.01036539 0.08624456]\n",
      "[0.77950954 0.00156497 0.16474593 0.00383554 0.00271608 0.04762793]\n",
      "[0.41486663 0.03185083 0.27474058 0.01521947 0.06359416 0.19972833]\n",
      "[0.6375141  0.01477941 0.1127237  0.01999121 0.04737721 0.16761431]\n",
      "[0.8224624  0.00362432 0.10369333 0.02589905 0.00272943 0.04159149]\n",
      "[0.902324   0.0013502  0.05551793 0.00234329 0.00205785 0.0364067 ]\n",
      "[0.02980064 0.06719185 0.03411928 0.01027106 0.01232563 0.8462915 ]\n",
      "[0.5516454  0.03099353 0.18151659 0.02152723 0.0309214  0.18339582]\n",
      "[0.02077698 0.64886004 0.03778726 0.21634069 0.00553883 0.07069625]\n",
      "[0.38942245 0.04004279 0.3360835  0.13183461 0.01244267 0.09017389]\n",
      "[0.00151842 0.94909346 0.00418695 0.00574947 0.00467889 0.03477262]\n",
      "[0.03392508 0.26145008 0.01664246 0.65642786 0.00258717 0.02896734]\n",
      "[0.07072014 0.16736577 0.29903707 0.2189822  0.10616378 0.13773099]\n",
      "[0.320115   0.00933296 0.5296939  0.08669178 0.01155822 0.04260818]\n",
      "[0.28339213 0.0794808  0.11480283 0.3677421  0.00324035 0.15134184]\n",
      "[0.18354839 0.20550555 0.07994451 0.38226497 0.01193859 0.13679813]\n",
      "[0.02957854 0.03157559 0.14859356 0.01350721 0.7250058  0.05173928]\n",
      "[0.09308533 0.02031704 0.3023355  0.01981061 0.5045465  0.05990502]\n",
      "[0.28066584 0.06065132 0.21063723 0.0916472  0.2598177  0.09658068]\n",
      "[0.20933184 0.03422324 0.12268449 0.2659239  0.31091228 0.05692422]\n",
      "[0.13996728 0.06164553 0.13902055 0.0607361  0.5086453  0.0899853 ]\n",
      "[0.26411945 0.06643932 0.09767921 0.11866833 0.36837336 0.08472037]\n",
      "[0.28272966 0.06966052 0.06609312 0.44254586 0.049047   0.08992387]\n",
      "[0.35688034 0.02970543 0.09745155 0.4251162  0.02127807 0.06956846]\n",
      "[0.12798843 0.36321142 0.09429287 0.3138729  0.04545387 0.0551805 ]\n",
      "[0.05053765 0.2619955  0.04225748 0.60729533 0.01244995 0.02546415]\n",
      "[0.55916613 0.08216192 0.11565301 0.11631432 0.02878039 0.0979242 ]\n",
      "[0.16389246 0.2865477  0.10038254 0.06650148 0.25629932 0.12637655]\n",
      "[0.02839071 0.32806447 0.02700452 0.5840179  0.0132271  0.01929529]\n",
      "[0.10425071 0.13697042 0.05646845 0.656315   0.01306381 0.03293157]\n",
      "[0.08633643 0.29997903 0.07642392 0.42889553 0.05704603 0.051319  ]\n",
      "[0.06299878 0.5231581  0.07053692 0.24127471 0.05485521 0.04717632]\n",
      "[5.9204173e-01 5.8087159e-04 3.7343967e-01 4.9578822e-03 1.2816737e-03\n",
      " 2.7698176e-02]\n",
      "[0.90247977 0.00125291 0.04776236 0.00305853 0.00109324 0.04435317]\n",
      "[0.81075597 0.01945676 0.03322632 0.03533074 0.01228122 0.08894912]\n",
      "[0.81064785 0.00802502 0.06207921 0.01882366 0.00872998 0.09169428]\n",
      "[7.7770239e-01 5.9264456e-04 2.0157626e-01 4.2653279e-03 8.9272403e-04\n",
      " 1.4970615e-02]\n",
      "[8.8456702e-01 5.3688785e-04 8.5400075e-02 2.4130398e-02 2.4021139e-04\n",
      " 5.1253922e-03]\n",
      "[0.60808045 0.00548663 0.2924594  0.02974627 0.01125812 0.05296911]\n",
      "[0.81888306 0.00561271 0.09833337 0.01611954 0.00543563 0.05561577]\n",
      "[0.36305174 0.06730922 0.23869489 0.06248448 0.05045412 0.21800555]\n",
      "[0.2687451  0.09376011 0.27719766 0.0744172  0.0932063  0.19267364]\n",
      "[0.91709906 0.0029071  0.03677675 0.01235173 0.00097681 0.02988849]\n",
      "[0.65493244 0.0007081  0.3280959  0.00287562 0.00158156 0.01180626]\n",
      "[0.54546666 0.00513409 0.18280478 0.24297714 0.00354135 0.02007599]\n",
      "[0.6587815  0.00895983 0.23338991 0.02368994 0.01490093 0.06027794]\n",
      "[0.7649661  0.00242537 0.20100306 0.01217377 0.00297861 0.01645312]\n",
      "[0.9159538  0.003708   0.02987362 0.02962484 0.00135269 0.0194871 ]\n",
      "[5.4058165e-04 9.7133684e-01 1.7672773e-03 2.5314572e-03 9.1312891e-03\n",
      " 1.4692570e-02]\n",
      "[0.01004982 0.64497596 0.01734956 0.00567427 0.03601457 0.28593573]\n",
      "[0.00173294 0.9112156  0.00577743 0.00435396 0.03397826 0.04294191]\n",
      "[0.14593844 0.4323643  0.05274718 0.03649128 0.0265963  0.3058624 ]\n",
      "[0.00163645 0.965851   0.00158822 0.0140921  0.00134124 0.01549096]\n",
      "[0.0349557  0.61180633 0.04141324 0.2239382  0.01347183 0.07441467]\n",
      "[0.07423595 0.58714    0.02895866 0.14386763 0.01554706 0.15025076]\n",
      "[0.02925877 0.7560492  0.00636163 0.02298141 0.0018307  0.1835184 ]\n",
      "[4.3553862e-04 9.7208977e-01 6.0091092e-04 5.0730254e-03 8.1406819e-04\n",
      " 2.0986663e-02]\n",
      "[0.02392773 0.6510892  0.01526265 0.14722493 0.0043188  0.15817674]\n",
      "[2.4105196e-03 9.1153485e-01 2.5835067e-03 5.4281715e-02 8.5221388e-04\n",
      " 2.8337289e-02]\n",
      "[1.5306482e-03 9.5642626e-01 5.8234867e-04 8.9434972e-03 3.6730950e-03\n",
      " 2.8844142e-02]\n",
      "[0.00185532 0.9286872  0.00656538 0.01815552 0.01428122 0.03045535]\n",
      "[0.05110135 0.50434476 0.06229683 0.19861479 0.05027034 0.13337189]\n",
      "[3.3039224e-04 9.6924454e-01 1.1414774e-03 2.7495350e-03 3.4630012e-03\n",
      " 2.3070998e-02]\n",
      "[0.01804271 0.8020031  0.01305522 0.04396493 0.01672972 0.10620438]\n",
      "[0.00118753 0.5761083  0.01892501 0.00814344 0.3834002  0.01223555]\n",
      "[0.0017608  0.6866179  0.01981034 0.01719967 0.25808364 0.01652761]\n",
      "[2.4198441e-04 8.7914866e-01 5.5068918e-03 1.1863062e-03 9.9638313e-02\n",
      " 1.4277940e-02]\n",
      "[5.7477519e-05 9.8434120e-01 4.0759883e-04 8.7804685e-04 9.2569729e-03\n",
      " 5.0585917e-03]\n",
      "[0.00320952 0.61124355 0.01994656 0.01953212 0.32800698 0.01806125]\n",
      "[2.5914474e-03 8.5705236e-02 9.6048666e-03 5.7533238e-04 8.8901401e-01\n",
      " 1.2509058e-02]\n",
      "[0.00100916 0.92216027 0.00383639 0.00484903 0.04560966 0.0225355 ]\n",
      "[0.00192035 0.6038502  0.0178999  0.00343342 0.34123376 0.03166235]\n",
      "[0.01246478 0.7222127  0.01170792 0.21495707 0.01010421 0.02855332]\n",
      "[0.08886342 0.2874075  0.12473883 0.08940677 0.27964523 0.12993823]\n",
      "[0.0251346  0.646334   0.05473563 0.04673732 0.15633242 0.070726  ]\n",
      "[0.01624565 0.7630788  0.01648157 0.02221143 0.08801702 0.09396542]\n",
      "[0.1524654  0.36583036 0.0654616  0.13221706 0.08004002 0.20398551]\n",
      "[0.04840319 0.46674308 0.05117152 0.02783513 0.27182022 0.1340269 ]\n",
      "[0.02300246 0.6079257  0.04442457 0.06601747 0.04495265 0.21367706]\n",
      "[0.06786854 0.40406764 0.07837357 0.08315448 0.19843182 0.16810395]\n",
      "[0.39595363 0.04875659 0.27446172 0.03292106 0.05384358 0.19406337]\n",
      "[0.26064682 0.04605395 0.29531458 0.15600088 0.0227292  0.21925457]\n",
      "[0.07627028 0.31391093 0.10736898 0.06875589 0.05038879 0.38330504]\n",
      "[0.24767129 0.17842788 0.17156449 0.11931271 0.03088234 0.25214127]\n",
      "[0.11212505 0.26005152 0.09488646 0.18110743 0.01605236 0.3357771 ]\n",
      "[0.1910311  0.16627236 0.16084078 0.21442032 0.02641879 0.24101672]\n",
      "[0.1845291  0.01681124 0.55167234 0.0073907  0.04343855 0.19615807]\n",
      "[0.12337779 0.0258047  0.4172221  0.00767154 0.02746715 0.3984567 ]\n",
      "[0.00687567 0.20308648 0.00402119 0.7733247  0.00120003 0.01149195]\n",
      "[2.6142258e-02 4.1224593e-03 5.5939080e-03 9.6114874e-01 3.9569795e-04\n",
      " 2.5969248e-03]\n",
      "[0.03570508 0.25195682 0.11899628 0.01470108 0.13394457 0.44469616]\n",
      "[0.071297   0.42635092 0.01791167 0.3176567  0.00614887 0.16063485]\n",
      "[0.08230487 0.1331792  0.04337828 0.6857669  0.00153058 0.0538402 ]\n",
      "[0.00449827 0.85415965 0.00857285 0.01985218 0.01263172 0.10028528]\n",
      "[0.21050188 0.04785883 0.01952849 0.5736557  0.00395241 0.14450262]\n",
      "[0.0228561  0.7651957  0.00397756 0.11526854 0.0067473  0.08595478]\n",
      "[0.16705456 0.02293764 0.440109   0.00522762 0.04547095 0.3192002 ]\n",
      "[0.18588917 0.07078071 0.28038144 0.01874599 0.09596328 0.34823942]\n",
      "[0.07392314 0.06537209 0.17012128 0.02266196 0.5118873  0.15603419]\n",
      "[0.21842799 0.02160988 0.23017049 0.01915011 0.40619385 0.10444774]\n",
      "[0.30703253 0.01952598 0.31527612 0.03872991 0.21873589 0.10069951]\n",
      "[0.17421761 0.09894922 0.13881448 0.2207656  0.2703191  0.09693402]\n",
      "[0.31054187 0.07008435 0.16980705 0.05189802 0.06579573 0.33187297]\n",
      "[0.5735559  0.0196071  0.2184026  0.06046074 0.01916313 0.10881051]\n",
      "[0.02820357 0.36507607 0.1444204  0.04549272 0.27979589 0.13701138]\n",
      "[0.06410109 0.12722798 0.40482113 0.02980561 0.26170063 0.11234348]\n",
      "[0.01364404 0.5366268  0.11062956 0.01287701 0.12387159 0.20235094]\n",
      "[0.00804645 0.57188165 0.07234362 0.02896427 0.2372198  0.08154414]\n",
      "[0.02778432 0.70594305 0.01037166 0.18949611 0.01729865 0.0491062 ]\n",
      "[0.13068758 0.10344868 0.10964043 0.5935481  0.01511796 0.04755718]\n",
      "[0.08880886 0.29622713 0.10813652 0.4434423  0.01816704 0.04521815]\n",
      "[0.05179143 0.13005643 0.28209838 0.45863366 0.03269867 0.04472156]\n",
      "[0.2194091  0.06612497 0.17884684 0.02363395 0.25381178 0.25817335]\n",
      "[0.46365952 0.02934033 0.19652057 0.09209225 0.1293584  0.089029  ]\n",
      "[0.04836973 0.01791849 0.44476256 0.00557866 0.39483488 0.08853574]\n",
      "[0.11232355 0.05746988 0.2772682  0.34733233 0.1322171  0.07338888]\n",
      "[0.19762573 0.07039106 0.07299753 0.5443655  0.06077497 0.05384521]\n",
      "[0.10062512 0.16336092 0.17024696 0.24171452 0.18056625 0.14348625]\n",
      "[0.15174496 0.06444108 0.18286127 0.20432122 0.29236937 0.10426205]\n",
      "[0.14599884 0.03786409 0.41913587 0.11378639 0.12493832 0.15827644]\n",
      "[0.04539703 0.6231802  0.04118618 0.09276644 0.0343533  0.16311681]\n",
      "[0.00652314 0.21839185 0.03602843 0.00359681 0.6885767  0.04688305]\n",
      "[0.36109465 0.05021786 0.20585866 0.0586891  0.01794571 0.306194  ]\n",
      "[0.03656054 0.2364225  0.09268083 0.00742249 0.45291436 0.17399926]\n",
      "[0.00711536 0.73001313 0.03578582 0.0178036  0.16449268 0.04478943]\n",
      "[0.00548418 0.8312704  0.01430638 0.10980191 0.01036023 0.0287769 ]\n",
      "[0.00533809 0.8000741  0.0133841  0.14100781 0.01073952 0.02945636]\n",
      "[0.00558593 0.74252343 0.01560792 0.19832295 0.00995748 0.02800227]\n",
      "[0.88762206 0.00248004 0.05084547 0.01106502 0.0015325  0.04645487]\n",
      "[0.46984968 0.04396389 0.15359095 0.02438726 0.08897978 0.21922845]\n",
      "[0.8816125  0.00443145 0.03001442 0.00469455 0.00228709 0.07696002]\n",
      "[0.55408335 0.01270691 0.1917099  0.00633681 0.0404367  0.19472633]\n",
      "[0.12061708 0.09123021 0.11351436 0.6008332  0.00726988 0.06653529]\n",
      "[0.13004489 0.19635151 0.04818056 0.50899196 0.01395883 0.10247226]\n",
      "[0.41793036 0.02877956 0.20563005 0.10587297 0.01119131 0.2305958 ]\n",
      "[0.34903005 0.01380023 0.43653497 0.04302994 0.02515246 0.13245243]\n",
      "[0.4431354  0.01874707 0.38138995 0.04664563 0.01587504 0.09420705]\n",
      "[0.52683395 0.02780212 0.19305542 0.04420651 0.00608439 0.20201766]\n",
      "[0.14990455 0.00477224 0.7399754  0.00947137 0.02665075 0.06922561]\n",
      "[0.4262028  0.02853255 0.28512055 0.09890138 0.05276457 0.10847815]\n",
      "[0.5367305  0.00958942 0.3422336  0.02666552 0.00813095 0.07664997]\n",
      "[0.3841955  0.03018133 0.18005207 0.31885964 0.01826468 0.06844674]\n",
      "[0.34494486 0.00494105 0.57423455 0.01354063 0.02024256 0.04209641]\n",
      "[0.14943965 0.07626452 0.4029453  0.0400811  0.08647034 0.24479908]\n",
      "[0.03514329 0.69245124 0.03079024 0.13393225 0.0189083  0.08877464]\n",
      "[0.5263705  0.0229469  0.22366014 0.07957344 0.04976092 0.09768801]\n",
      "[0.16307852 0.1384226  0.10916324 0.49713963 0.03215452 0.06004152]\n",
      "[0.42015782 0.05364578 0.14617124 0.21063162 0.05240093 0.11699255]\n",
      "[0.00470491 0.35518357 0.0077245  0.62168914 0.00316077 0.00753713]\n",
      "[0.00728581 0.16467969 0.0092742  0.8118403  0.00289843 0.00402152]\n",
      "[0.05834241 0.08303164 0.01521376 0.8029693  0.00426914 0.03617375]\n",
      "[2.4480717e-03 2.0642763e-01 1.4140935e-03 7.8756511e-01 3.9942827e-04\n",
      " 1.7457063e-03]\n",
      "[0.01766218 0.64902925 0.02818375 0.07473128 0.02649458 0.20389898]\n",
      "[1.4254977e-02 4.8505273e-02 2.2310568e-02 9.0999800e-01 4.6597866e-04\n",
      " 4.4652033e-03]\n",
      "[0.00284109 0.871471   0.01895523 0.01438926 0.02495033 0.06739312]\n",
      "[0.01292804 0.65625805 0.0109624  0.08562407 0.0059133  0.22831419]\n",
      "[0.09383871 0.04625143 0.07531008 0.7504768  0.00270249 0.03142052]\n",
      "[9.4731059e-03 6.6157351e-03 8.8607548e-03 9.7310513e-01 3.3335856e-04\n",
      " 1.6118630e-03]\n",
      "[0.05844608 0.09523558 0.04363575 0.7721452  0.00237454 0.02816287]\n",
      "[0.02998434 0.30045825 0.07709338 0.5279697  0.0120563  0.05243794]\n",
      "[4.8237160e-04 8.5099822e-01 6.9249226e-03 5.4843011e-03 1.2894399e-01\n",
      " 7.1660755e-03]\n",
      "[6.7242520e-04 8.6428231e-01 1.5492196e-02 1.7474649e-02 9.2859551e-02\n",
      " 9.2189666e-03]\n",
      "[0.00822473 0.4903484  0.02878481 0.06813116 0.38826242 0.01624842]\n",
      "[0.00261301 0.8444209  0.01672453 0.02509253 0.08836076 0.02278839]\n",
      "[0.00111544 0.0834232  0.00535391 0.9038217  0.0043231  0.00196268]\n",
      "[0.00768315 0.09903937 0.0191641  0.85246956 0.01277822 0.00886561]\n",
      "[3.8851830e-04 8.0745417e-01 7.7945320e-03 1.5582626e-01 2.3481028e-02\n",
      " 5.0555747e-03]\n",
      "[0.00130219 0.7328443  0.00965267 0.22035488 0.0275151  0.00833077]\n",
      "[0.00426163 0.7205207  0.0184269  0.16059329 0.08109871 0.01509875]\n",
      "[0.01476787 0.1678188  0.01280196 0.7872502  0.00631793 0.01104323]\n",
      "[0.01243572 0.65310436 0.03030909 0.20074552 0.07795083 0.02545451]\n",
      "[0.02928037 0.36298501 0.0213553  0.5401749  0.02999974 0.01620473]\n",
      "[1.0887724e-04 9.5985109e-01 4.8244299e-04 3.5778530e-02 1.0626325e-03\n",
      " 2.7164503e-03]\n",
      "[0.00131162 0.63139194 0.00226647 0.35745478 0.00297852 0.00459677]\n",
      "[0.00167746 0.18990608 0.0025931  0.80173993 0.00098944 0.00309392]\n",
      "[4.8805322e-04 9.6893811e-01 1.2628738e-03 8.6560333e-03 1.2332977e-02\n",
      " 8.3219651e-03]\n",
      "[0.00494616 0.9014412  0.01049234 0.04274708 0.00516618 0.03520703]\n",
      "[0.00104915 0.9391296  0.00132331 0.04770239 0.00166732 0.00912833]\n",
      "[0.00225109 0.9236911  0.00399083 0.01433219 0.00819675 0.04753804]\n",
      "[0.04815626 0.46317142 0.07079414 0.11796043 0.14884281 0.15107478]\n",
      "[0.03518521 0.52801794 0.04143278 0.12874193 0.01128473 0.25533742]\n",
      "[0.01045818 0.7789432  0.01448694 0.10452897 0.00850118 0.08308166]\n",
      "[0.0057968  0.84493166 0.02196163 0.05286072 0.02574753 0.04870184]\n",
      "[2.6304551e-04 9.7852039e-01 7.3877699e-04 1.0252981e-02 1.6376234e-03\n",
      " 8.5871881e-03]\n",
      "[0.1301684  0.0921845  0.38694358 0.19931844 0.0439182  0.14746682]\n",
      "[0.15619564 0.05348319 0.066156   0.67265046 0.00618863 0.04532607]\n",
      "[0.5388256  0.0047802  0.26809826 0.13980748 0.00369293 0.04479562]\n",
      "[0.02637258 0.3291774  0.02569061 0.56095505 0.00398144 0.05382299]\n",
      "[0.30989197 0.03053463 0.25741825 0.19942355 0.00637936 0.1963522 ]\n",
      "[0.03139871 0.10830728 0.03814495 0.7926481  0.00175868 0.02774231]\n",
      "[0.1578717  0.16640931 0.1179525  0.44010627 0.01599848 0.10166169]\n",
      "[0.04654748 0.06573322 0.06668729 0.77014995 0.01242933 0.03845277]\n",
      "[0.1267128  0.08005966 0.12604876 0.01524678 0.08446182 0.56747013]\n",
      "[0.0182302  0.20368823 0.18759884 0.00985311 0.44801846 0.13261117]\n",
      "[1.9783829e-03 4.6609428e-02 4.8184223e-02 5.3035206e-04 8.8189185e-01\n",
      " 2.0805815e-02]\n",
      "[0.01583174 0.41645077 0.10680305 0.00949821 0.36624393 0.0851723 ]\n",
      "[0.15591669 0.08540951 0.18592669 0.01169254 0.11502953 0.44602504]\n",
      "[0.05453368 0.028296   0.3813064  0.00720418 0.36747515 0.1611847 ]\n",
      "[0.0372346  0.02930574 0.09922644 0.00613658 0.6709413  0.15715532]\n",
      "[0.01192133 0.06317947 0.10348016 0.00360071 0.7478122  0.07000612]\n",
      "[8.4332022e-04 1.7131889e-02 4.5441478e-02 1.6773528e-04 9.2822182e-01\n",
      " 8.1936764e-03]\n",
      "[0.03719745 0.03600379 0.24912012 0.00166711 0.58798707 0.0880245 ]\n",
      "[0.25651664 0.05503499 0.22721976 0.01419774 0.1360323  0.31099865]\n",
      "[0.10303308 0.10819261 0.24652979 0.052898   0.24634834 0.24299814]\n",
      "[0.01927728 0.02894546 0.06734084 0.00552656 0.8325089  0.04640096]\n",
      "[0.01734567 0.04085788 0.20134611 0.00554389 0.6623152  0.07259127]\n",
      "[7.0758918e-03 1.3669669e-02 3.3403467e-02 5.2044180e-04 9.2714351e-01\n",
      " 1.8187065e-02]\n",
      "[0.18305115 0.08467442 0.19774538 0.01445504 0.40209663 0.11797745]\n",
      "[0.33665085 0.06393868 0.13649127 0.01436367 0.11439384 0.33416173]\n",
      "[0.20789658 0.00266476 0.5758921  0.00393075 0.01918096 0.19043493]\n",
      "[0.0490097  0.04424347 0.09791986 0.01257925 0.7015384  0.09470934]\n",
      "[0.01611316 0.22164817 0.21706125 0.00684946 0.38330343 0.15502448]\n",
      "[0.00821769 0.03262321 0.06602946 0.00092801 0.8626793  0.0295223 ]\n",
      "[0.00184307 0.8509323  0.01515329 0.00662268 0.09648278 0.02896592]\n",
      "[0.23576018 0.06602498 0.15629636 0.00815439 0.15762782 0.3761362 ]\n",
      "[0.27923432 0.02726432 0.3448835  0.03947272 0.04593919 0.263206  ]\n",
      "[0.7471179  0.0033912  0.1086181  0.00484807 0.00936039 0.12666444]\n",
      "[0.47338146 0.0390724  0.08287566 0.03920262 0.02626353 0.33920437]\n",
      "[0.2650695  0.07657307 0.16177195 0.02794102 0.15958299 0.30906144]\n",
      "[0.18134822 0.06610123 0.26998454 0.02422668 0.1358337  0.3225057 ]\n",
      "[0.77141476 0.00199898 0.16181737 0.00418093 0.0077256  0.05286227]\n",
      "[0.6260166  0.0121907  0.12516034 0.00743399 0.02968466 0.19951372]\n",
      "[0.30410776 0.00638997 0.4001543  0.00392483 0.02857442 0.25684872]\n",
      "[0.33005026 0.01918776 0.35082024 0.01497608 0.05822197 0.2267437 ]\n",
      "[0.03042063 0.11963093 0.17658453 0.00451565 0.27989376 0.38895458]\n",
      "[0.01313929 0.31956843 0.11191664 0.00915264 0.38049427 0.16572872]\n",
      "[0.05088343 0.05944729 0.28281352 0.0039962  0.3357914  0.26706815]\n",
      "[0.01000015 0.38709688 0.09979964 0.00426743 0.2037993  0.29503652]\n",
      "[0.03180534 0.06853353 0.2895755  0.01409596 0.15352774 0.4424619 ]\n",
      "[4.4859160e-05 9.8661232e-01 1.7721782e-04 7.3035219e-04 6.9478701e-04\n",
      " 1.1740486e-02]\n",
      "[0.01020312 0.64944476 0.06467942 0.06886646 0.10760593 0.09920029]\n",
      "[0.00262179 0.87501967 0.00837529 0.0152506  0.01657707 0.08215566]\n",
      "[0.01819444 0.1218337  0.07132783 0.01721222 0.70020705 0.07122479]\n",
      "[0.01016944 0.17283456 0.09097932 0.04669945 0.64496356 0.03435358]\n",
      "[0.00654394 0.10979418 0.21710314 0.01910958 0.58839667 0.0590525 ]\n",
      "[0.00131206 0.02613786 0.01252495 0.00129467 0.95110273 0.00762782]\n",
      "[0.08207078 0.05020875 0.06086009 0.70229834 0.05770753 0.04685455]\n",
      "[0.04955567 0.10843317 0.15166801 0.53772897 0.08158959 0.07102465]\n",
      "[0.03958036 0.09876003 0.03276424 0.7693928  0.02794176 0.03156078]\n",
      "[0.02288253 0.13707002 0.01807268 0.7533507  0.04438161 0.0242425 ]\n",
      "[0.02667468 0.21245354 0.12179458 0.00356571 0.432949   0.2025624 ]\n",
      "[0.03794005 0.3341915  0.13129905 0.00654421 0.28456897 0.20545615]\n",
      "[0.05981006 0.08349352 0.16319153 0.00727608 0.51466984 0.17155898]\n",
      "[0.07896667 0.16362248 0.09264159 0.00495024 0.3590524  0.3007666 ]\n",
      "[0.16074155 0.19862315 0.10900784 0.03080484 0.2717346  0.22908801]\n",
      "[0.11654986 0.21993487 0.12953947 0.02307067 0.35376883 0.1571363 ]\n",
      "[0.11278142 0.3322418  0.07035799 0.02493905 0.14272311 0.31695655]\n",
      "[0.06585301 0.59798986 0.07235225 0.04959256 0.07611718 0.1380951 ]\n",
      "[0.12492461 0.00735538 0.54093385 0.00295615 0.02306139 0.30076867]\n",
      "[0.1023558  0.07895541 0.27869967 0.02764509 0.10598952 0.4063544 ]\n",
      "[0.48431468 0.02093066 0.26784438 0.02887113 0.02501682 0.17302231]\n",
      "[6.3695475e-02 5.5105909e-04 8.8625288e-01 9.8510424e-04 5.0135138e-03\n",
      " 4.3501936e-02]\n",
      "[0.5068259  0.0090374  0.29336804 0.00362812 0.03165707 0.15548347]\n",
      "[0.7825025  0.00381626 0.14173049 0.00538715 0.00661186 0.05995173]\n",
      "[7.2888654e-01 6.5972953e-04 2.4191706e-01 2.1179402e-03 1.3508748e-03\n",
      " 2.5067735e-02]\n",
      "[0.64016545 0.00379367 0.2472762  0.00300679 0.01675658 0.08900137]\n",
      "[0.1597592  0.015218   0.46860433 0.01102245 0.06622831 0.27916777]\n",
      "[0.06534929 0.5088447  0.01756305 0.0415501  0.0104512  0.35624173]\n",
      "[0.04668174 0.03376694 0.37300414 0.00654937 0.26248223 0.27751556]\n",
      "[0.09552969 0.00171147 0.8504347  0.00390749 0.00804307 0.0403736 ]\n",
      "[0.61133206 0.03023066 0.04259997 0.03793781 0.00152681 0.27637258]\n",
      "[0.0824692  0.305121   0.12202128 0.02562871 0.0376549  0.4271049 ]\n",
      "[0.2798407  0.06024322 0.07164983 0.02791603 0.0294737  0.5308765 ]\n",
      "[0.09997299 0.10254887 0.15725988 0.01478636 0.03380863 0.59162325]\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "for i in predictions:\n",
    "    print(i)\n",
    "    y_pred.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67fc44ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=np.array(y_pred)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34ace08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4128787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_accuracy=accuracy_score(main_labels_test,y_pred)\n",
    "#print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c232a42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  5  3  9  5  1]\n",
      " [ 1 34  3  4  1  5]\n",
      " [13  9  9  8  6  3]\n",
      " [ 4 23  1 20  0  0]\n",
      " [ 1  2  4  0 13  4]\n",
      " [10  8  7  4 11  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(main_labels_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c3e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
